{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df293246",
   "metadata": {},
   "source": [
    "# Laboration: CNN Tolkbarhet, Activation Maximization & DeepDream\n",
    "\n",
    "Denna notebook redovisar lösningen för laborationen i djupinlärning. Vi utforskar hur VGG16 \"ser\" bilder genom Feature Attribution (CAM), visualiserar vad specifika filter reagerar på med Activation Maximization, och skapar konstnärliga bilder med DeepDream.\n",
    "\n",
    "projektet är uppdelat i enlighet med kraven:\n",
    "- **G-del**: Feature Attribution (CAM/Grad-CAM)\n",
    "- **VG-del**: Activation Maximization & DeepDream\n",
    "\n",
    "**Notera om Hårdvara:**\n",
    "Koden är anpassad för att använda **Nvidia RTX 5080** (Blackwell/sm_120) om drivrutiner och PyTorch-version tillåter. Vi har installerat en Nightly-build av PyTorch (cu126) för att maximera kompatibilitet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lägg till src i path så vi kan importera våra moduler\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from src.model import load_model\n",
    "from src.preprocessing import load_image, show_image\n",
    "\n",
    "# Setup Enhet\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Använder enhet: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Ladda modell\n",
    "try:\n",
    "    model = load_model(device)\n",
    "except Exception as e:\n",
    "    print(f\"Kunde inte ladda modell på GPU (kanske inkompatibel drivrutin/PTX): {e}\")\n",
    "    print(\"Faller tillbaka till CPU...\")\n",
    "    device = torch.device('cpu')\n",
    "    model = load_model(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e31f72",
   "metadata": {},
   "source": [
    "## 1. Data och Preprocessing\n",
    "Vi laddar in två testbilder: en hund (golden retriever) och ett slott/landskap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sökvägar\n",
    "img_path1 = '../data/images/dog.png'\n",
    "img_path2 = '../data/images/castle.png'\n",
    "\n",
    "# Ladda bilder\n",
    "img_tensor1 = load_image(img_path1, device)\n",
    "img_tensor2 = load_image(img_path2, device)\n",
    "\n",
    "print(\"Originalbilder:\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "show_image(img_tensor1, \"Bild 1: Hund\")\n",
    "plt.subplot(1, 2, 2)\n",
    "show_image(img_tensor2, \"Bild 2: Slott\")\n",
    "plt.show() # Visar separat om figuren ovan inte ritar direkt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814d94a",
   "metadata": {},
   "source": [
    "## Del G: Feature Attribution (CAM)\n",
    "Här visualiserar vi var modellen \"tittar\" för att klassificera bilderna. Vi använder **Smooth Grad-CAM++** och jämför två olika lager i VGG16.\n",
    "\n",
    "**Lager vi undersöker:**\n",
    "1. `features.28` (Sista conv-lagret): Bör visa semantiska delar (huvud, kropp etc.)\n",
    "2. `features.10` (Tidigare lager): Bör visa mer generella mönster eller texturer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f488c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cam import generate_cam, visualize_cam\n",
    "\n",
    "# Funktion för att köra experiment\n",
    "def run_cam_experiment(img_tensor, layer_name, title_suffix=\"\"):\n",
    "    print(f\"--- CAM för lager {layer_name} ---\")\n",
    "    heatmap = generate_cam(model, img_tensor, target_layer=layer_name)\n",
    "    visualize_cam(heatmap, img_tensor, title=f\"CAM {layer_name} {title_suffix}\")\n",
    "\n",
    "# Experiment 1: Hund\n",
    "print(\"Analyserar Bild 1 (Hund)...\")\n",
    "run_cam_experiment(img_tensor1, 'features.28', \"(Sista Conv)\")\n",
    "run_cam_experiment(img_tensor1, 'features.10', \"(Tidigt Lager)\")\n",
    "\n",
    "# Experiment 2: Slott\n",
    "print(\"Analyserar Bild 2 (Slott)...\")\n",
    "run_cam_experiment(img_tensor2, 'features.28', \"(Sista Conv)\")\n",
    "run_cam_experiment(img_tensor2, 'features.10', \"(Tidigt Lager)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be29d66f",
   "metadata": {},
   "source": [
    "### Analys av CAM\n",
    "Genom att jämföra värmekartorna kan vi tydligt se VGG16:s hierarkiska struktur:\n",
    "\n",
    "**Lager 10 (features.10) - Tidigt konvolutionellt lager:**\n",
    "- Aktiveras på **texturer och enkla mönster**\n",
    "- Spridda aktiveringar över hela bilden\n",
    "- Reagerar på kanter, hörn och ytor\n",
    "- *Exempel*: På hundbilden aktiveras lager av pälsstrukturer och kantlinjer\n",
    "\n",
    "**Lager 28 (features.28) - Sista konvolutionella lager:**\n",
    "- Mycket **fokuserade aktiveringar på relevanta objekt**\n",
    "- Semantisk förståelse: hittar hela delar av objektet\n",
    "- *Exempel*: På hundbilden koncentreras aktivering kring hundens huvud, ögon och nos\n",
    "- På slottsbilden aktiveras torn, fönster och arkitektoniska detaljer\n",
    "\n",
    "**Insikt:** CNN:n bygger upp förståelse från enkla features (lager 10) till komplexa semantiska koncept (lager 28). Detta är precis vad vi förväntar oss av en djup nätverksarkitektur!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e6947",
   "metadata": {},
   "source": [
    "## Del VG: Activation Maximization\n",
    "Här \"vänder vi på steken\" och optimerar en *input-bild* (från brus) för att maximera aktiveringen av ett specifikt filter. Detta visar oss vad filtret \"letar efter\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.activation_maximization import activation_maximization\n",
    "\n",
    "# Testa flera lager för att visa hierarki\n",
    "layers_to_test = ['features.5', 'features.10', 'features.20', 'features.28']\n",
    "filters_per_layer = {\n",
    "    'features.5': [0, 10, 20],      # Tidiga lager: enkla mönster\n",
    "    'features.10': [15, 45, 80],    # Mellanlager: texturer\n",
    "    'features.20': [100, 200, 300], # Djupare lager: komplexa former\n",
    "    'features.28': [15, 60, 250]    # Sista lagret: semantiska delar\n",
    "}\n",
    "\n",
    "# Skapa figur för alla resultat\n",
    "fig, axes = plt.subplots(len(layers_to_test), 3, figsize=(15, 5 * len(layers_to_test)))\n",
    "fig.suptitle('Activation Maximization - Hierarki av Features', fontsize=16)\n",
    "\n",
    "for i, layer in enumerate(layers_to_test):\n",
    "    filters = filters_per_layer[layer]\n",
    "    for j, f_idx in enumerate(filters):\n",
    "        print(f\"Maximerar filter {f_idx} i {layer}...\")\n",
    "        try:\n",
    "            am_img = activation_maximization(model, layer, f_idx, iterations=100, device=device)\n",
    "        except Exception as e:\n",
    "            print(f\"Fel vid AM på {device}: {e}, testar CPU...\")\n",
    "            am_img = activation_maximization(model.to('cpu'), layer, f_idx, iterations=100, device='cpu')\n",
    "            model.to(device)\n",
    "        \n",
    "        axes[i, j].imshow(am_img)\n",
    "        axes[i, j].set_title(f\"Lager {layer.split('.')[1]}: Filter {f_idx}\", fontsize=10)\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ace761",
   "metadata": {},
   "source": [
    "## Del VG: DeepDream\n",
    "DeepDream bygger vidare på activation maximization men appliceras på en bild (oftast) och använder \"oktaver\" (multi-scale) för att skapa komplexa, fraktala mönster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.deep_dream import deep_dream\n",
    "\n",
    "# Vi drömmer på vår slottsbild!\n",
    "print(\"Startar DeepDream på slottsbilden...\")\n",
    "layers_to_dream = ['features.24', 'features.28'] # Blanda lite lager\n",
    "\n",
    "try:\n",
    "    dream_img = deep_dream(model, img_tensor2, layers_to_dream, iterations=10, num_octaves=3, device=device)\n",
    "except Exception as e:\n",
    "    print(f\"Fel vid DeepDream på {device}: {e}. Kör på CPU (kan ta tid)...\")\n",
    "    dream_img = deep_dream(model.to('cpu'), img_tensor2.to('cpu'), layers_to_dream, iterations=10, num_octaves=3, device='cpu')\n",
    "    model.to(device)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(dream_img)\n",
    "plt.title(\"DeepDream Resultat\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Spara resultatet\n",
    "# (Här skulle vi spara till fil om vi ville)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c057cc5",
   "metadata": {},
   "source": [
    "## Slutsats\n",
    "\n",
    "Vi har lyckats implementera och köra både feature attribution och activation maximization. Resultaten visar tydligt modellens hierarkiska uppbyggnad. DeepDream ger visuellt intressanta tolkningar av vad modellen ser i bilden.\n",
    "\n",
    "### Key Insikter:\n",
    "\n",
    "**1. Hierarkisk feature-lärande:**\n",
    "- Tidiga lager (features.5): Detekterar grundläggande element som linjer och kanter\n",
    "- Mellanlager (features.10-20): Kombinerar till texturer och mönster\n",
    "- Sena lager (features.28): Förstår komplexa semantiska koncept\n",
    "\n",
    "**2. Filter-specialisering:**\n",
    "- Vissa filter är specialiserade på cirkulära former (ögon, torn)\n",
    "- Andra reagerar på texturer (päls, stenar)\n",
    "- Några filter hittar kombinationer av former och färger\n",
    "\n",
    "**3. DeepDream som kreativt verktyg:**\n",
    "- Förstärker det modellen redan \"ser\" i bilder\n",
    "- Skapar surrealistiska men meningsfulla visualiseringar\n",
    "- Visar nätverkets inre \"fantasi\"\n",
    "\n",
    "### Tekniska framgångar:\n",
    "- ✅ Gradient ascent implementerat från grunden\n",
    "- ✅ Multi-scale DeepDream med jitter och oktaver\n",
    "- ✅ Progression-tracking för activation maximization\n",
    "- ✅ Systematisk analys av flera lager\n",
    "\n",
    "Projektet demonstrerar hur vi kan \"titta in\" i svarta lådor och förstå vad neurala nätverk lär sig!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
