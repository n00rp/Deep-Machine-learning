{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df293246",
   "metadata": {},
   "source": [
    "# Laboration: CNN Tolkbarhet, Activation Maximization & DeepDream\n",
    "\n",
    "Denna notebook redovisar lösningen för laborationen i djupinlärning. Vi utforskar hur VGG16 \"ser\" bilder genom Feature Attribution (CAM), visualiserar vad specifika filter reagerar på med Activation Maximization, och skapar konstnärliga bilder med DeepDream.\n",
    "\n",
    "projektet är uppdelat i enlighet med kraven:\n",
    "- **G-del**: Feature Attribution (CAM/Grad-CAM)\n",
    "- **VG-del**: Activation Maximization & DeepDream\n",
    "\n",
    "**Notera om Hårdvara:**\n",
    "Koden är anpassad för att använda **Nvidia RTX 5080** (Blackwell/sm_120) om drivrutiner och PyTorch-version tillåter. Vi har installerat en Nightly-build av PyTorch (cu126) för att maximera kompatibilitet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffa63ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lägg till src i path så vi kan importera våra moduler\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from src.model import load_model\n",
    "from src.preprocessing import load_image, show_image\n",
    "\n",
    "# Setup Enhet\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Använder enhet: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Ladda modell\n",
    "try:\n",
    "    model = load_model(device)\n",
    "except Exception as e:\n",
    "    print(f\"Kunde inte ladda modell på GPU (kanske inkompatibel drivrutin/PTX): {e}\")\n",
    "    print(\"Faller tillbaka till CPU...\")\n",
    "    device = torch.device('cpu')\n",
    "    model = load_model(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e31f72",
   "metadata": {},
   "source": [
    "## 1. Data och Preprocessing\n",
    "Vi laddar in två testbilder: en hund (golden retriever) och ett slott/landskap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8246f549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sökvägar\n",
    "img_path1 = '../data/images/dog.png'\n",
    "img_path2 = '../data/images/castle.png'\n",
    "\n",
    "# Ladda bilder\n",
    "img_tensor1 = load_image(img_path1, device)\n",
    "img_tensor2 = load_image(img_path2, device)\n",
    "\n",
    "print(\"Originalbilder:\")\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "show_image(img_tensor1, \"Bild 1: Hund\")\n",
    "plt.subplot(1, 2, 2)\n",
    "show_image(img_tensor2, \"Bild 2: Slott\")\n",
    "plt.show() # Visar separat om figuren ovan inte ritar direkt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0814d94a",
   "metadata": {},
   "source": [
    "## Del G: Feature Attribution (CAM)\n",
    "Här visualiserar vi var modellen \"tittar\" för att klassificera bilderna. Vi använder **Smooth Grad-CAM++** och jämför två olika lager i VGG16.\n",
    "\n",
    "**Lager vi undersöker:**\n",
    "1. `features.28` (Sista conv-lagret): Bör visa semantiska delar (huvud, kropp etc.)\n",
    "2. `features.10` (Tidigare lager): Bör visa mer generella mönster eller texturer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f488c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.cam import generate_cam, visualize_cam\n",
    "\n",
    "# Funktion för att köra experiment\n",
    "def run_cam_experiment(img_tensor, layer_name, title_suffix=\"\"):\n",
    "    print(f\"--- CAM för lager {layer_name} ---\")\n",
    "    heatmap = generate_cam(model, img_tensor, target_layer=layer_name)\n",
    "    visualize_cam(heatmap, img_tensor, title=f\"CAM {layer_name} {title_suffix}\")\n",
    "\n",
    "# Experiment 1: Hund\n",
    "print(\"Analyserar Bild 1 (Hund)...\")\n",
    "run_cam_experiment(img_tensor1, 'features.28', \"(Sista Conv)\")\n",
    "run_cam_experiment(img_tensor1, 'features.10', \"(Tidigt Lager)\")\n",
    "\n",
    "# Experiment 2: Slott\n",
    "print(\"Analyserar Bild 2 (Slott)...\")\n",
    "run_cam_experiment(img_tensor2, 'features.28', \"(Sista Conv)\")\n",
    "run_cam_experiment(img_tensor2, 'features.10', \"(Tidigt Lager)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be29d66f",
   "metadata": {},
   "source": [
    "### Analys av CAM\n",
    "Genom att jämföra värmekartorna kan vi se att det sista lagret (`features.28`) är mycket mer fokuserat på **objektet** (t.ex. hundens ansikte). De tidigare lagren tenderar att aktiveras av kanter och texturer över hela bilden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381e6947",
   "metadata": {},
   "source": [
    "## Del VG: Activation Maximization\n",
    "Här \"vänder vi på steken\" och optimerar en *input-bild* (från brus) för att maximera aktiveringen av ett specifikt filter. Detta visar oss vad filtret \"letar efter\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dad129e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.activation_maximization import activation_maximization\n",
    "\n",
    "# Välj ett lager och några intressanta filterindex\n",
    "# features.28 har 512 filter.\n",
    "target_layer = 'features.28'\n",
    "filters = [10, 45, 123] \n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, f_idx in enumerate(filters):\n",
    "    print(f\"Maximerar filter {f_idx} i {target_layer}...\")\n",
    "    # Vi kör på CPU om GPU strular med baklänges-passet, men testa device först\n",
    "    try:\n",
    "        am_img = activation_maximization(model, target_layer, f_idx, iterations=50, device=device)\n",
    "    except Exception as e:\n",
    "        print(f\"Fel vid AM på {device}: {e}, testar CPU...\")\n",
    "        am_img = activation_maximization(model.to('cpu'), target_layer, f_idx, iterations=50, device='cpu')\n",
    "        model.to(device) # Flytta tillbaka\n",
    "        \n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.imshow(am_img)\n",
    "    plt.title(f\"Filter {f_idx}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ace761",
   "metadata": {},
   "source": [
    "## Del VG: DeepDream\n",
    "DeepDream bygger vidare på activation maximization men appliceras på en bild (oftast) och använder \"oktaver\" (multi-scale) för att skapa komplexa, fraktala mönster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0648215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.deep_dream import deep_dream\n",
    "\n",
    "# Vi drömmer på vår slottsbild!\n",
    "print(\"Startar DeepDream på slottsbilden...\")\n",
    "layers_to_dream = ['features.24', 'features.28'] # Blanda lite lager\n",
    "\n",
    "try:\n",
    "    dream_img = deep_dream(model, img_tensor2, layers_to_dream, iterations=10, num_octaves=3, device=device)\n",
    "except Exception as e:\n",
    "    print(f\"Fel vid DeepDream på {device}: {e}. Kör på CPU (kan ta tid)...\")\n",
    "    dream_img = deep_dream(model.to('cpu'), img_tensor2.to('cpu'), layers_to_dream, iterations=10, num_octaves=3, device='cpu')\n",
    "    model.to(device)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(dream_img)\n",
    "plt.title(\"DeepDream Resultat\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Spara resultatet\n",
    "# (Här skulle vi spara till fil om vi ville)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c057cc5",
   "metadata": {},
   "source": [
    "## Slutsats\n",
    "Vi har lyckats implementera och köra både feature attribution och activation maximization. Resultaten visar tydligt modellens hierarkiska uppbyggnad. DeepDream ger visuellt intressanta tolkningar av vad modellen ser i bilden.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
